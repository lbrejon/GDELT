{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import socket\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.utils.utils import save_csv, load_yaml, save_yaml, load_pickle, save_pickle\n",
    "from src.utils.utils import create_directory, download_file_from_url, unzip_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find .env automagically by walking up directories until it's found, then load up the .env entries as environment variables\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "project_dir = os.path.join(os.path.dirname('.env'), os.pardir)\n",
    "\n",
    "DATA_DIR = os.path.join(project_dir, os.environ.get(\"DATA_DIR\"))\n",
    "CONFIG_DIR = os.path.join(project_dir, os.environ.get(\"CONFIG_DIR\"))\n",
    "EXTERNAL_DATA_DIR = os.path.join(project_dir, os.environ.get(\"EXTERNAL_DATA_DIR\"))\n",
    "RAW_DATA_DIR = os.path.join(project_dir, os.environ.get(\"RAW_DATA_DIR\"))\n",
    "PROCESSED_DATA_DIR = os.path.join(project_dir, os.environ.get(\"PROCESSED_DATA_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_ZIP_DATA_DIR = RAW_DATA_DIR + 'zip/'\n",
    "RAW_CSV_DATA_DIR = RAW_DATA_DIR + 'csv/'\n",
    "\n",
    "AWS_ACCESS_KEY_ID = load_yaml(CONFIG_DIR+'secret.yml')['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = load_yaml(CONFIG_DIR+'secret.yml')['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150383</td>\n",
       "      <td>297a16b493de7cf6ca809a7cc31d0b93</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318084</td>\n",
       "      <td>bb27f78ba45f69a17ea6ed7755e9f8ff</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10768507</td>\n",
       "      <td>ea8dde0beb0ba98810a92db068c0ce99</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149211</td>\n",
       "      <td>2a91041d7e72b0fc6a629e2ff867b240</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339037</td>\n",
       "      <td>dec3f427076b716a8112b9086c342523</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814731</th>\n",
       "      <td>108304</td>\n",
       "      <td>81dbf12b7dae6baa0cac2d2f9d5ef42c</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/202301131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814732</th>\n",
       "      <td>5336143</td>\n",
       "      <td>22c9f0e26855dcbd48a0f3c7a3d91906</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/202301131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814733</th>\n",
       "      <td>77342</td>\n",
       "      <td>0c14e3c325fc7a064e851e9fe0f05734</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/202301131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814734</th>\n",
       "      <td>128699</td>\n",
       "      <td>669f07e39c97541f908c5b3aaad00d43</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/202301131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814735</th>\n",
       "      <td>5810853</td>\n",
       "      <td>55c5368a04353a893b7db8443e99b15b</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/202301131...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        something                                id  \\\n",
       "0          150383  297a16b493de7cf6ca809a7cc31d0b93   \n",
       "1          318084  bb27f78ba45f69a17ea6ed7755e9f8ff   \n",
       "2        10768507  ea8dde0beb0ba98810a92db068c0ce99   \n",
       "3          149211  2a91041d7e72b0fc6a629e2ff867b240   \n",
       "4          339037  dec3f427076b716a8112b9086c342523   \n",
       "...           ...                               ...   \n",
       "814731     108304  81dbf12b7dae6baa0cac2d2f9d5ef42c   \n",
       "814732    5336143  22c9f0e26855dcbd48a0f3c7a3d91906   \n",
       "814733      77342  0c14e3c325fc7a064e851e9fe0f05734   \n",
       "814734     128699  669f07e39c97541f908c5b3aaad00d43   \n",
       "814735    5810853  55c5368a04353a893b7db8443e99b15b   \n",
       "\n",
       "                                                      url  \n",
       "0       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "1       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "2       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "3       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "4       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "...                                                   ...  \n",
       "814731  http://data.gdeltproject.org/gdeltv2/202301131...  \n",
       "814732  http://data.gdeltproject.org/gdeltv2/202301131...  \n",
       "814733  http://data.gdeltproject.org/gdeltv2/202301131...  \n",
       "814734  http://data.gdeltproject.org/gdeltv2/202301131...  \n",
       "814735  http://data.gdeltproject.org/gdeltv2/202301131...  \n",
       "\n",
       "[814736 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(RAW_DATA_DIR, 'master_file_list.txt')\n",
    "df = pd.read_csv(file_path, sep=' ', header=None, names=['something', 'id', 'url'])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split rows into hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_host_file(hosts_no, df):\n",
    "    hosts = [f'tp-hadoop-{host_no}' for host_no in hosts_no]\n",
    "    rows_splits = np.array_split(range(df.shape[0]), len(hosts))\n",
    "    hosts2rows = dict(zip(hosts, rows_splits))\n",
    "    return hosts2rows\n",
    "\n",
    "\n",
    "def split_data_per_host(df, hosts_file_path, hosts_no=None, verbose=False):\n",
    "    if not os.path.isfile(hosts_file_path):\n",
    "        if hosts_no is None:\n",
    "            raise ValueError(\"Select host numero for 'tp-hadoop-XX' (Example: [43, 54, 55, 30]\")\n",
    "        hosts2rows = create_host_file(hosts_no, df)\n",
    "        save_pickle(hosts2rows, pickle_path=hosts_file_path)\n",
    "    else:\n",
    "        hosts2rows = load_pickle(hosts_file_path)\n",
    "\n",
    "    if verbose:\n",
    "        for host, rows in hosts2rows.items():\n",
    "            logging.info(f\"Host '{host}': {len(rows)} rows.\")\n",
    "            \n",
    "    return hosts2rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts_file_path = CONFIG_DIR + 'hosts.pkl'\n",
    "hosts_no = [43, 54, 55, 30]\n",
    "hosts2rows = split_data_per_host(df, hosts_file_path, hosts_no=hosts_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150383</td>\n",
       "      <td>297a16b493de7cf6ca809a7cc31d0b93</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318084</td>\n",
       "      <td>bb27f78ba45f69a17ea6ed7755e9f8ff</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10768507</td>\n",
       "      <td>ea8dde0beb0ba98810a92db068c0ce99</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149211</td>\n",
       "      <td>2a91041d7e72b0fc6a629e2ff867b240</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339037</td>\n",
       "      <td>dec3f427076b716a8112b9086c342523</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201502182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203679</th>\n",
       "      <td>9509730</td>\n",
       "      <td>6fbf31cdaf0f56a551b47639cc87f292</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201701281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203680</th>\n",
       "      <td>123516</td>\n",
       "      <td>1c25357d1672fd2196baa741de88f3c0</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201701281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203681</th>\n",
       "      <td>276332</td>\n",
       "      <td>b95c8cff24387a537af808dbe5fe6dea</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201701281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203682</th>\n",
       "      <td>10104191</td>\n",
       "      <td>cc20f52ec30f42d570d10f9cd7f2d4ed</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201701281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203683</th>\n",
       "      <td>97278</td>\n",
       "      <td>c3fda390e4bc65850d8d3ffcb521d7a8</td>\n",
       "      <td>http://data.gdeltproject.org/gdeltv2/201701281...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203684 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        something                                id  \\\n",
       "0          150383  297a16b493de7cf6ca809a7cc31d0b93   \n",
       "1          318084  bb27f78ba45f69a17ea6ed7755e9f8ff   \n",
       "2        10768507  ea8dde0beb0ba98810a92db068c0ce99   \n",
       "3          149211  2a91041d7e72b0fc6a629e2ff867b240   \n",
       "4          339037  dec3f427076b716a8112b9086c342523   \n",
       "...           ...                               ...   \n",
       "203679    9509730  6fbf31cdaf0f56a551b47639cc87f292   \n",
       "203680     123516  1c25357d1672fd2196baa741de88f3c0   \n",
       "203681     276332  b95c8cff24387a537af808dbe5fe6dea   \n",
       "203682   10104191  cc20f52ec30f42d570d10f9cd7f2d4ed   \n",
       "203683      97278  c3fda390e4bc65850d8d3ffcb521d7a8   \n",
       "\n",
       "                                                      url  \n",
       "0       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "1       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "2       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "3       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "4       http://data.gdeltproject.org/gdeltv2/201502182...  \n",
       "...                                                   ...  \n",
       "203679  http://data.gdeltproject.org/gdeltv2/201701281...  \n",
       "203680  http://data.gdeltproject.org/gdeltv2/201701281...  \n",
       "203681  http://data.gdeltproject.org/gdeltv2/201701281...  \n",
       "203682  http://data.gdeltproject.org/gdeltv2/201701281...  \n",
       "203683  http://data.gdeltproject.org/gdeltv2/201701281...  \n",
       "\n",
       "[203684 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_name = 'tp-hadoop-43'\n",
    "# host_name = socket.gethostname()\n",
    "df_host = df.iloc[hosts2rows[host_name]].copy()\n",
    "df_host"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowload data from web to local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_bucket(bucket_name=\"bucket-nosql\"):\n",
    "    s3 = boto3.resource(\n",
    "            service_name='s3', region_name='eu-west-1',\n",
    "            aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "        )\n",
    "    my_bucket = s3.Bucket(bucket_name)\n",
    "    bucket_files = [my_bucket_object.key for my_bucket_object in my_bucket.objects.all()]\n",
    "    return bucket_files\n",
    "\n",
    "\n",
    "\n",
    "def get_csv_category(csv_filename, pattern=r'\\.(.*?)\\.'):\n",
    "    category = re.findall(pattern, csv_filename)\n",
    "    return category[0]\n",
    "\n",
    "\n",
    "\n",
    "def download_data_from_web(urls_to_process, bucket_files, n_urls=None):\n",
    "    urls_to_process = urls_to_process[:n_urls]\n",
    "\n",
    "    for row, url in enumerate(urls_to_process):\n",
    "        zip_file_path = os.path.join(RAW_ZIP_DATA_DIR, Path(url).name)\n",
    "        csv_file_path = os.path.join(RAW_CSV_DATA_DIR, Path(url).stem)\n",
    "        aws_filename = get_csv_category(Path(url).stem) + \"/\" + Path(url).stem\n",
    "        \n",
    "        if aws_filename not in bucket_files:\n",
    "            \n",
    "            # Download data from remote url to data/raw/zip\n",
    "            create_directory(RAW_ZIP_DATA_DIR)\n",
    "            if not os.path.isfile(zip_file_path):\n",
    "                download_file_from_url(remote_url=url, local_dir=RAW_ZIP_DATA_DIR, verbose=True)\n",
    "            else:\n",
    "                print(f\"[{row+1}/{len(urls_to_process)}] File '{zip_file_path}' already exists.\")\n",
    "\n",
    "            # Unzip file within data/raw/url to data/raw/csv\n",
    "            create_directory(RAW_CSV_DATA_DIR)\n",
    "            if not os.path.isfile(csv_file_path):\n",
    "                unzip_file(zip_file_path, RAW_CSV_DATA_DIR, verbose=True)\n",
    "            else:\n",
    "                print(f\"[{row+1}/{len(urls_to_process)}] File '{csv_file_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['export/20150218230000.export.CSV',\n",
       " 'export/20150218231500.export.CSV',\n",
       " 'export/20150218233000.export.CSV',\n",
       " 'export/20150218234500.export.CSV',\n",
       " 'gkg/20150218230000.gkg.csv',\n",
       " 'gkg/20150218231500.gkg.csv',\n",
       " 'gkg/20150218233000.gkg.csv',\n",
       " 'mentions/20150218230000.mentions.CSV',\n",
       " 'mentions/20150218231500.mentions.CSV',\n",
       " 'mentions/20150218233000.mentions.CSV']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"bucket-nosql\"\n",
    "bucket_files = get_files_in_bucket(bucket_name)\n",
    "bucket_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_urls = 10\n",
    "urls_to_process = df_host['url'].tolist()\n",
    "download_data_from_web(urls_to_process, bucket_files, n_urls=n_urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data from local computer to AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client(\n",
    "        service_name='s3', region_name='eu-west-1',\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY \n",
    "    )\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def upload_file_to_S3_bucket(csv_files, bucket_name):\n",
    "    bucket_files = get_files_in_bucket(bucket_name)\n",
    "    for no, filename in enumerate(csv_files):\n",
    "        file_path_csv = RAW_CSV_DATA_DIR + filename\n",
    "        file_path_zip = RAW_ZIP_DATA_DIR + filename + '.zip'\n",
    "        object_name = f\"{get_csv_category(filename)}/{filename}\"\n",
    "\n",
    "        # Upload csv file from local computer to AWS S3 bucket    \n",
    "        if object_name not in bucket_files:\n",
    "            upload_file(file_path_csv, bucket_name, object_name=object_name)\n",
    "            os.remove(file_path_csv)\n",
    "            os.remove(file_path_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files into AWS S3 bucket\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['export/20150218230000.export.CSV',\n",
       " 'export/20150218231500.export.CSV',\n",
       " 'export/20150218233000.export.CSV',\n",
       " 'export/20150218234500.export.CSV',\n",
       " 'gkg/20150218230000.gkg.csv',\n",
       " 'gkg/20150218231500.gkg.csv',\n",
       " 'gkg/20150218233000.gkg.csv',\n",
       " 'mentions/20150218230000.mentions.CSV',\n",
       " 'mentions/20150218231500.mentions.CSV',\n",
       " 'mentions/20150218233000.mentions.CSV']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = [f for f in os.listdir(RAW_CSV_DATA_DIR)]\n",
    "upload_file_to_S3_bucket(csv_files, bucket_name)\n",
    "            \n",
    "bucket_files = get_files_in_bucket(bucket_name)\n",
    "n_files_in_bucket = len(bucket_files)\n",
    "print(f\"{n_files_in_bucket} files into AWS S3 bucket\")\n",
    "bucket_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh lbrejon-21@tp-1a252-20.enst.fr\n",
    "# ssh lbrejon-21@tp-1a252-21.enst.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /home/users/lbrejon-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh lbrejon-21@ssh.enst.fr \n",
    "# ssh ubuntu@137.194.211.146\n",
    "# ssh tp-hadoop-55"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_telecom_paris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1438fcff661187e962cd90992d5b725d8668c00dc3f5feaddb6740b55bd88082"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
